{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(\"../\")\n",
    "from utils import *\n",
    "from model import *\n",
    "from loss import *\n",
    "from dataset import *\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "root_dir = '/home/harsh/Downloads/ModelNet10/ModelNet10/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "alpha = 0.0001\n",
    "train_tfms = transforms.Compose([PointSampler(1024),TrainTransforms()])\n",
    "test_tfms = transforms.Compose([PointSampler(1024),TestTransforms()])\n",
    "train_ds = ModelNet10(root_dir = root_dir,folder='train',transforms=train_tfms)\n",
    "test_ds = ModelNet10(root_dir = root_dir,folder = 'test',transforms=test_tfms)\n",
    "\n",
    "train_dl = DataLoader(train_ds,batch_size = bs,shuffle = True)\n",
    "test_dl = DataLoader(test_ds,batch_size = bs,shuffle = True)\n",
    "\n",
    "model = PointNet(classes = len(train_ds.classes)).cuda()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optim,step_size=20,gamma=0.5)\n",
    "criterion = PointNetLoss(alpha=alpha)\n",
    "\n",
    "writer = SummaryWriter('runs/experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3991"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.290147304534912\n",
      "26.005099534988403\n",
      "37.39424753189087\n",
      "47.57975745201111\n",
      "66.77631998062134\n",
      "76.27570962905884\n",
      "89.76783919334412\n",
      "102.06793427467346\n",
      "114.94538903236389\n",
      "132.9121754169464\n",
      "142.79286360740662\n",
      "159.13141894340515\n",
      "171.93074584007263\n",
      "185.2412657737732\n",
      "193.21211695671082\n",
      "207.36930203437805\n",
      "220.70982003211975\n",
      "241.55277729034424\n",
      "261.37028551101685\n",
      "275.3287544250488\n",
      "292.59160590171814\n",
      "307.9662289619446\n",
      "320.85010838508606\n",
      "336.19637274742126\n",
      "349.2273952960968\n",
      "361.66480922698975\n",
      "374.90638613700867\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    av_tr_loss = 0\n",
    "    train_acc = 0\n",
    "    tic = time.time()\n",
    "    \n",
    "    for i,(pointclouds,labels) in enumerate(train_dl):\n",
    "        optim.zero_grad()\n",
    "        pointclouds = pointclouds.type(torch.FloatTensor)\n",
    "        outputs,m3,m64 = model(pointclouds.cuda())\n",
    "        loss = criterion(outputs,labels.cuda(),m3,m64)\n",
    "        av_tr_loss += loss.item()\n",
    "        acc = torch.sum(torch.argmax(outputs.cpu(),dim = 1) == labels)\n",
    "        train_acc += acc\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "        toc = time.time()\n",
    "        print(toc-tic)\n",
    "#     if (epoch+1)%5 == 0:\n",
    "#         model.eval()\n",
    "#         av_test_loss = 0\n",
    "#         test_acc = 0\n",
    "#         with torch.no_grad():\n",
    "#             for i,(pointclouds,labels) in enumerate(test_dl):\n",
    "#                 pointclouds = pointclouds.type(torch.FloatTensor)\n",
    "#                 outputs,m3,m64 = model(pointclouds.cuda())\n",
    "#                 loss_test = criterion(outputs,labels.cuda(),m3,m64)\n",
    "#                 av_test_loss += loss_test.item()\n",
    "#                 test_acc += torch.sum(torch.argmax(outputs.cpu(),dim = 1) == labels.cuda())\n",
    "\n",
    "#         print(\"Epoch [{}/{}] --> Testing Loss:{}, Testing Accuracy:{}\".format(epoch,epochs,av_test_loss/len(test_ds), test_acc/len(test_ds)))\n",
    "#         writer.add_scalar('Test Loss',av_test_loss/len(test_ds),epoch//5 + 1)\n",
    "#         writer.add_scalar('Test acc',test_acc/len(test_ds),epoch//5 + 1)\n",
    "#     writer.add_scalar('Train Loss',av_tr_loss/len(train_ds),epoch)\n",
    "#     writer.add_scalar('Train acc',train_acc/len(train_ds),epoch)\n",
    "    \n",
    "#     print(\"Epoch [{}/{}] --> Training Loss:{:.2f}, Testing Accuracy:{:.2f}\".format(epoch,epochs,av_tr_loss/len(train_ds), train_acc/len(train_ds)))\n",
    "# writer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
